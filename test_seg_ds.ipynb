{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\justm\\OneDrive\\Desktop\\Luna Grand Chalenge\\test_seg_ds.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/justm/OneDrive/Desktop/Luna%20Grand%20Chalenge/test_seg_ds.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/justm/OneDrive/Desktop/Luna%20Grand%20Chalenge/test_seg_ds.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/justm/OneDrive/Desktop/Luna%20Grand%20Chalenge/test_seg_ds.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/justm/OneDrive/Desktop/Luna%20Grand%20Chalenge/test_seg_ds.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/justm/OneDrive/Desktop/Luna%20Grand%20Chalenge/test_seg_ds.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32mc:\\Users\\justm\\OneDrive\\Desktop\\Luna Grand Chalenge\\.venv\\Lib\\site-packages\\pandas\\__init__.py:151\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomputation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39meval\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    135\u001b[0m     concat,\n\u001b[0;32m    136\u001b[0m     lreshape,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m     qcut,\n\u001b[0;32m    149\u001b[0m )\n\u001b[1;32m--> 151\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[0;32m    152\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m testing\n\u001b[0;32m    153\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_print_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n",
      "File \u001b[1;32mc:\\Users\\justm\\OneDrive\\Desktop\\Luna Grand Chalenge\\.venv\\Lib\\site-packages\\pandas\\api\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\" public toolkit API \"\"\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     extensions,\n\u001b[0;32m      4\u001b[0m     indexers,\n\u001b[0;32m      5\u001b[0m     interchange,\n\u001b[0;32m      6\u001b[0m     types,\n\u001b[0;32m      7\u001b[0m     typing,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minterchange\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mextensions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtyping\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m ]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "import glob\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nodule_classifier.dsetsG import CTScan, create_df_candidates_info\n",
    "from util.utilG import getCacheHandle, unzipped_path, xyz2irc\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# log = logging.getLogger('ggggg')\n",
    "# # log.setLevel(logging.WARN)\n",
    "# # log.setLevel(logging.INFO)\n",
    "# log.setLevel(logging.DEBUG)\n",
    "\n",
    "disk_cache = getCacheHandle('segmentation')\n",
    "\n",
    "\n",
    "def get_candidate_info(series_uid):\n",
    "    df_candidates = create_df_candidates_info()\n",
    "    return df_candidates.loc[series_uid].values.tolist()\n",
    "\n",
    "class CTScan_seg(CTScan):\n",
    "    def __init__(self, series_uid) -> None:\n",
    "        self.seriesuid = series_uid\n",
    "        path_mhdfile = glob.glob(unzipped_path + 'subset*/subset*/{}.mhd'.format(series_uid))[0]\n",
    "        ct_img = sitk.ReadImage(path_mhdfile) #contain metadata getters\n",
    "        ct_img_arr = sitk.GetArrayFromImage(ct_img).astype(np.float32)\n",
    "        self.ct_img_arr = ct_img_arr\n",
    "         # no longer clip hu [-1000, 1000] here \n",
    "         # because we want to keep the original values of the CT scan\n",
    "        \n",
    "        self.origin_xyz = np.array(ct_img.GetOrigin())\n",
    "        self.vxSize_xyz = np.array(ct_img.GetSpacing())\n",
    "        self.direction_matrix = np.array(ct_img.GetDirection()).reshape(3, 3)\n",
    "        \n",
    "        candidateInfo_list = get_candidate_info(series_uid) # for 1 ct uid only\n",
    "        \n",
    "        \"\"\"idea: build a mask of the positive candidates, \n",
    "        then get the indexes of the mask by summing over the axis 1 and 2, \n",
    "        since the mask is 1 where the pixel is positive, and 0 where the pixel is negative\"\"\"\n",
    "        self.positiveInfo_list = [candidate_tup for candidate_tup \n",
    "                                  in candidateInfo_list if candidate_tup.isNodule_bool]\n",
    "        self.positive_mask = self.buildAnnotationMask(self.positiveInfo_list)\n",
    "        self.positive_indexes = (self.positive_mask.sum(axis=(1,2))\n",
    "                                 .nonzero()[0].tolist()) # get the Is in IRC of the positive masks\n",
    "\n",
    "    def buildAnnotationMask(self, positiveInfo_list, threshold_hu = -700): \n",
    "        #need to fix the bug of wrapping around at 0 index of the tensor\n",
    "        mask_arr = np.zeros_like(self.ct_img_arr, dtype=bool)\n",
    "        \"\"\"So, a HU value of -700 is less dense than water, air, and lung tissue. It's much less dense than bone or other soft tissues. In the context of a lung CT scan, a HU value of -700 would likely correspond to very low-density tissue or possibly an area of disease or damage.\"\"\"\n",
    "        for candidateInfo_tup in positiveInfo_list: \n",
    "            #loop over all the positive candidates of a single chosen ct scan, \n",
    "            # the positiveInfo_list is filtered to only \n",
    "            # contain candidates of a single ct series uid \n",
    "            center_irc = xyz2irc(\n",
    "                candidateInfo_tup.center_xyz,\n",
    "                self.origin_xyz,\n",
    "                self.vxSize_xyz,\n",
    "                self.direction_matrix,\n",
    "            )\n",
    "            ci = int(center_irc.index)\n",
    "            cr = int(center_irc.row)\n",
    "            cc = int(center_irc.col)\n",
    "            # from the center of the candidate, \n",
    "            # we expand the bounding box until we reach the threshold_hu\n",
    "            # we do this for all 3 axes, and we stop expanding an axis once one direction \n",
    "            # of a given axis reaches the threshold_hu, and continue to the next axis\n",
    "            index_step = 2\n",
    "            try: # we loop until we touch the threshold_hu\n",
    "                while self.ct_img_arr[ci + index_step, cr, cc] > threshold_hu and \\\n",
    "                        self.ct_img_arr[ci - index_step, cr, cc] > threshold_hu:\n",
    "                    index_step += 1\n",
    "            except IndexError: #indexError is raised when we reach the end of the axis\n",
    "                index_step -= 1\n",
    "\n",
    "            row_step = 2\n",
    "            try:\n",
    "                while self.ct_img_arr[ci, cr + row_step, cc] > threshold_hu and \\\n",
    "                        self.ct_img_arr[ci, cr - row_step, cc] > threshold_hu:\n",
    "                    row_step += 1\n",
    "            except IndexError:\n",
    "                row_step -= 1\n",
    "\n",
    "            col_step = 2\n",
    "            try:\n",
    "                while self.ct_img_arr[ci, cr, cc + col_step] > threshold_hu and \\\n",
    "                        self.ct_img_arr[ci, cr, cc - col_step] > threshold_hu:\n",
    "                    col_step += 1\n",
    "            except IndexError:\n",
    "                col_step -= 1\n",
    "\n",
    "            \"\"\"mask_arr is a 3d tensor of the same size as the ct, and that is False everywhere except where the candidate is located,\"\"\"\n",
    "            mask_arr[ \n",
    "                ci - index_step: ci + index_step + 1,\n",
    "                cr - row_step: cr + row_step + 1,\n",
    "                cc - col_step: cc + col_step + 1] = True\n",
    "        # need to do clean up because we stop expanding the bounding box when we reach the # threshold_hu without decreasing the increased step\n",
    "        # filter out the low density boxes that are bordering the high density boxes\n",
    "        mask_arr = mask_arr & (self.ct_img_arr > threshold_hu) # clean up bordering low density boxes\n",
    "        \n",
    "        \"\"\"we return the full mask, and we do the cropping on both the CT scan and the mask when we actually get the candidate chunk. (in ct.get_ct_cropped method)\"\"\"\n",
    "        return mask_arr       \n",
    "\n",
    "    @disk_cache.memoize(typed=True) \n",
    "    #cache this for fast retrieval of Index axis size and pos idxs\n",
    "    # we need the Index axis size because each ct scan has different number of slices\n",
    "    def get_Ct_I_axis_info(series_uid):\n",
    "        ct = CTScan_seg(series_uid)\n",
    "        return int(ct.ct_img_arr.shape[0]), ct.positive_indexes\n",
    "\n",
    "\n",
    "holder = create_df_candidates_info() #anti pattern, should fix this\n",
    "class LunaSegDataset(Dataset):\n",
    "    #custome implementation of a dataset that loads the CT scans and candidate info\n",
    "    \n",
    "    \n",
    "    # df_candidates = create_df_candidates_info().sample(frac=1) \n",
    "    \"\"\"we have to perform stratified split on the dataset, because the dataset is extremely imbalanced\"\"\"\n",
    "    df_candidates = holder\n",
    "    # num_samples = int(0.7 * len(df_candidates)) # lambda will automatically look for instance attributes\n",
    "    grouped = df_candidates.groupby('isNodule')\n",
    "    df_train = grouped.apply(lambda x: x.sample(int(int(0.7 * len(holder)) * len(x) / len(holder))), include_groups=False) \\\n",
    "        .reset_index(drop=False, inplace=False)\n",
    "    df_val = df_candidates.drop(df_train.index).reset_index(drop=False, inplace=False)\n",
    "    \n",
    "    \n",
    "    # dataloader probably does shallow copy of the object when numworkers > 0\n",
    "    # so df_candidates must stay outside of __init__ for it to be copied to each worker\n",
    "    def __init__(self, *, frac=.7, balance=True) -> None:\n",
    "        # if not hasattr(LunaDataset, 'df_candidates') or LunaDataset.df_candidates is None:\n",
    "        #     LunaDataset.df_candidates = create_df_candidates_info() # no copy, beware\n",
    "        #     LunaDataset.df_candidates = self.df_candidates.sample(frac=1) #shuffle\n",
    "        # self.frac_split_idx = int(frac * len(self.df_candidates))\n",
    "        self.balance = balance\n",
    "        self.positives, self.negatives = self.split_neg_pos(self.df_candidates)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df_candidates)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.balance:\n",
    "            pos_idx = idx // (self.balance + 1) \n",
    "            # every balance + 1 samples, we will have a positive sample\n",
    "\n",
    "            if idx % (self.balance + 1):\n",
    "                neg_idx = idx - 1 - pos_idx # adjust the idx \n",
    "                neg_idx %= len(self.negatives)\n",
    "                candidateInfo = self.negatives.iloc[neg_idx]\n",
    "            else:\n",
    "                pos_idx %= len(self.positives) #pos_list is small, so need to wraps around, otherwise will overflow\n",
    "                candidateInfo = self.positives.iloc[pos_idx]\n",
    "        else: # if balance is fasle, then we don't need to balance the dataset\n",
    "            # this is for validation set\n",
    "            candidateInfo = self.df_candidates.iloc[idx]\n",
    "            \n",
    "        ct_cropped = get_ct_cropped_disk_cache(candidateInfo['seriesuid'], candidateInfo['xyzCoord'])\n",
    "        ct_cropped = torch.tensor(ct_cropped).unsqueeze(0) # add channel input dimension\n",
    "\n",
    "        \n",
    "        isNodule_label = candidateInfo['isNodule']\n",
    "        # one_hot_encoding_tensor = F.one_hot(labels).to(torch.float32)\n",
    "        \n",
    "        # one_hot_encoding_tensor = torch.tensor([0, 1]) if isNodule_label else torch.tensor([1, 0])\n",
    "        # one_hot_encoding_tensor = one_hot_encoding_tensor.to(torch.long)\n",
    "        \n",
    "        one_hot_encoding_tensor = torch.tensor(isNodule_label).to(torch.long)\n",
    "        return ct_cropped, one_hot_encoding_tensor\n",
    "    \n",
    "    def split_neg_pos(self, df_candidates) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        return (df_candidates[self.df_candidates['isNodule']], \n",
    "                df_candidates[~self.df_candidates['isNodule']])\n",
    "        \n",
    "\n",
    "\n",
    "# training and validation datasets classes, which share the same parent self.df_candidates, \n",
    "# but the shared df_candidates is splitted\n",
    "class LunaSegDataset_Train(LunaSegDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(balance=True)\n",
    "        # self.df_candidates = self.df_candidates[:self.frac_split_idx]\n",
    "        self.df_candidates = self.df_train\n",
    "        self.positives, self.negatives = self.split_neg_pos(self.df_candidates)\n",
    "        \n",
    "        \n",
    "class LunaSegDataset_Val(LunaSegDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(balance=False)\n",
    "        # self.df_candidates = self.df_candidates[self.frac_split_idx:]\n",
    "        self.df_candidates = self.df_val\n",
    "        # self.positives, self.negatives = self.split_neg_pos(self.df_candidates)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
