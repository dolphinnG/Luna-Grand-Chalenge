{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import logging\n",
    "# import os\n",
    "\n",
    "# import numpy as np\n",
    "# from dsetsG import LunaDataset, LunaDataset_Train, LunaDataset_Val\n",
    "# from test.model import LunaModel\n",
    "# import torch\n",
    "# from  torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "# from util.utilG import enumerateWithEstimate\n",
    "\n",
    "# log = logging.getLogger('TrainingLoop')\n",
    "# # log.setLevel(logging.WARN)\n",
    "# log.setLevel(logging.INFO)\n",
    "# # log.setLevel(logging.DEBUG)\n",
    "# Y_TRUE = 0\n",
    "# Y_PRED = 1\n",
    "# LOSS = 2\n",
    "# class TrainingLoop:\n",
    "#     def __init__(self, model, optimizer, loss_fn, train_loader, val_loader):\n",
    "#         self.model = model\n",
    "#         self.optimizer = optimizer\n",
    "#         self.loss_fn = loss_fn\n",
    "#         self.train_loader = train_loader\n",
    "#         self.val_loader = val_loader\n",
    "#         self.use_cuda = torch.cuda.is_available()\n",
    "#         self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "#         self.trn_writer = None\n",
    "#         self.val_writer = None\n",
    "        \n",
    "    \n",
    "#     def run(self, epochs=1):\n",
    "        \n",
    "#         self.model.to(self.device)\n",
    "            \n",
    "#         for epoch_idx in range(1, epochs + 1):\n",
    "            \n",
    "#             #training\n",
    "#             epoch_metrics_tensor_train = torch.zeros(3, len(self.train_loader.dataset)) \n",
    "#             # we want the number of samples, not the number of batches\n",
    "#             self.model.train()\n",
    "#             for batch in enumerateWithEstimate(self.train_loader, f\"EPOCH_train: {epoch_idx}\"):\n",
    "#                 self.optimizer.zero_grad()\n",
    "#                 loss_scalar = self.compute_batch_loss_and_populate_metrics(batch, epoch_metrics_tensor_train)\n",
    "#                 loss_scalar.backward()\n",
    "#                 self.optimizer.step()\n",
    "#             self.logMetrics(epoch_idx, 'trn', epoch_metrics_tensor_train)\n",
    "            \n",
    "#             #validation\n",
    "#             epoch_metrics_tensor_val = torch.zeros(3, len(self.val_loader.dataset))\n",
    "#             self.model.eval()\n",
    "#             for batch in enumerateWithEstimate(self.val_loader, f\"EPOCH_val: {epoch_idx}\"):\n",
    "#                 with torch.no_grad():\n",
    "#                     self.compute_batch_loss_and_populate_metrics(batch, epoch_metrics_tensor_val)\n",
    "#             self.logMetrics(epoch_idx, 'val', epoch_metrics_tensor_val)             \n",
    "                    \n",
    "#         if hasattr(self, 'trn_writer'):\n",
    "#             assert self.trn_writer and self.val_writer\n",
    "#             self.trn_writer.close()\n",
    "#             self.val_writer.close()\n",
    "    \n",
    "#     def compute_batch_loss_and_populate_metrics(self, batch, epoch_metrics_tensor):\n",
    "#         batch_idx, batch_data = batch\n",
    "#         inputs, y_true = batch_data\n",
    "        \n",
    "#         y_pred_logits, y_pred_prob = self.model(inputs.to(self.device)) \n",
    "#         # loss_tensor = self.loss_fn(y_pred_logits, y_true[:, 1]) #could have used nn.NLLLoss() \n",
    "#         loss_tensor = self.loss_fn(y_pred_logits, y_true.to(self.device)) #could have used nn.NLLLoss() \n",
    "        \n",
    "#         slice_start = batch_idx * self.train_loader.batch_size\n",
    "#         slice_end = slice_start + len(y_true)\n",
    "#         epoch_metrics_tensor[LOSS, slice_start:slice_end] = loss_tensor.detach()\n",
    "#         # epoch_metrics_tensor[Y_TRUE, slice_start:slice_end] = y_true[:, 1].detach()\n",
    "#         epoch_metrics_tensor[Y_TRUE, slice_start:slice_end] = y_true.detach()\n",
    "#         epoch_metrics_tensor[Y_PRED, slice_start:slice_end] = y_pred_prob[:, 1].detach()\n",
    "        \n",
    "#         return loss_tensor.mean() # reduce to scalar\n",
    "    \n",
    "#     def logMetrics( # log metrics for each epoch\n",
    "#             self,\n",
    "#             epoch_ndx,\n",
    "#             mode_str,\n",
    "#             metrics_t,\n",
    "#             classificationThreshold=0.5,\n",
    "#     ):\n",
    "#         if self.trn_writer is None:\n",
    "#             log_dir = os.path.join('runs', 'Nodule_Classifier', \n",
    "#                                    datetime.datetime.now().strftime('%Y-%m-%d_%H.%M.%S'))\n",
    "\n",
    "#             self.trn_writer = SummaryWriter(\n",
    "#                 log_dir=log_dir + '-trn_cls-' + 'Nodule_Classifier')\n",
    "#             self.val_writer = SummaryWriter(\n",
    "#                 log_dir=log_dir + '-val_cls-' + 'Nodule_Classifier')\n",
    "#         log.info(\"E{} {}\".format(\n",
    "#             epoch_ndx,\n",
    "#             type(self).__name__,\n",
    "#         ))\n",
    "\n",
    "#         negLabel_mask = metrics_t[Y_TRUE] <= classificationThreshold #groundtruth negative\n",
    "#         negPred_mask = metrics_t[Y_PRED] <= classificationThreshold #prediction negative\n",
    "\n",
    "#         posLabel_mask = ~negLabel_mask\n",
    "#         posPred_mask = ~negPred_mask\n",
    "\n",
    "#         neg_count = int(negLabel_mask.sum())\n",
    "#         pos_count = int(posLabel_mask.sum())\n",
    "\n",
    "#         neg_correct = trueNeg = int((negLabel_mask & negPred_mask).sum()) #true negatives\n",
    "#         pos_correct = truePos = int((posLabel_mask & posPred_mask).sum()) #true positives\n",
    "\n",
    "#         falsePos = neg_count - trueNeg\n",
    "#         falseNeg = pos_count - truePos\n",
    "        \n",
    "#         metrics_dict = {}\n",
    "#         metrics_dict['loss_all'] = \\\n",
    "#             metrics_t[LOSS].mean() #avg loss per epoch of all batches\n",
    "#         metrics_dict['loss_negClass'] = \\\n",
    "#             metrics_t[LOSS, negLabel_mask].mean() #avg loss per epoch of negative class of all batches\n",
    "#         metrics_dict['loss_posClass'] = \\\n",
    "#             metrics_t[LOSS, posLabel_mask].mean() #avg loss per epoch of positive class of all batches\n",
    "\n",
    "#         # metrics_dict['correct/all'] = (pos_correct + neg_correct) \\\n",
    "#         #     / np.float32(metrics_t.shape[1]) * 100 # all correct predictions / all predictions\n",
    "#         metrics_dict['correct_all_accuracy'] = (truePos + trueNeg) / np.float32(pos_count + neg_count) * 100\n",
    "#         # metrics_dict['correct/neg'] = trueNeg / np.float32(neg_count) * 100 # true negatives / all actual negatives = specificity = true nagative rate\n",
    "#         metrics_dict['specificity'] = trueNeg / np.float32(trueNeg + falsePos) * 100 #true nagative rate\n",
    "#         # metrics_dict['correct/pos'] = pos_correct / np.float32(pos_count) * 100 # true positives / all actual positives = recall = true positive rate\n",
    "#         metrics_dict['recall'] = truePos / np.float32(truePos + falseNeg) \n",
    "#         metrics_dict['recall_pct'] = metrics_dict['recall'] * 100\n",
    "    \n",
    "#         metrics_dict['precision'] = truePos / np.float32(truePos + falsePos) \n",
    "#         metrics_dict['f1_score'] = (2 * (metrics_dict['precision'] * metrics_dict['recall']) \n",
    "#                                     / np.float32(metrics_dict['precision'] + metrics_dict['recall']))\n",
    "        \n",
    "        \n",
    "#         log.info(\n",
    "#             (\"E{} {:8} {loss_all:.4f} loss, \"\n",
    "#                   \"{correct_all_accuracy:-5.1f}% accuracy, \"\n",
    "#                   \"{recall:.4f} recall, \"\n",
    "#                   \"{precision:.4f} precision, \"\n",
    "#                     \"{f1_score:.4f} f1_score\"\n",
    "#             ).format(\n",
    "#                 epoch_ndx,\n",
    "#                 mode_str,\n",
    "#                 **metrics_dict,\n",
    "#             )\n",
    "#         )\n",
    "#         log.info(\n",
    "#             (\"E{} {:8} {loss_negClass:.4f} loss, \"\n",
    "#                 \"{specificity:-5.1f}% correct ({neg_correct:} of {neg_count:})\"\n",
    "#             ).format(\n",
    "#                 epoch_ndx,\n",
    "#                 mode_str + '_neg',\n",
    "#                 neg_correct=trueNeg,\n",
    "#                 neg_count=neg_count,\n",
    "#                 **metrics_dict,\n",
    "#             )\n",
    "#         )\n",
    "#         log.info(\n",
    "#             (\"E{} {:8} {loss_posClass:.4f} loss, \"\n",
    "#                 \"{recall_pct:-5.1f}% correct ({pos_correct:} of {pos_count:})\"\n",
    "#             ).format(\n",
    "#                 epoch_ndx,\n",
    "#                 mode_str + '_pos',\n",
    "#                 pos_correct=truePos,\n",
    "#                 pos_count=pos_count,\n",
    "#                 **metrics_dict,\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#         writer:SummaryWriter = getattr(self, mode_str + '_writer')\n",
    "         \n",
    "#         for key, value in metrics_dict.items():\n",
    "#             writer.add_scalar(key, value, epoch_ndx)\n",
    "\n",
    "#         writer.add_pr_curve(\n",
    "#             'pr',\n",
    "#             metrics_t[Y_TRUE],\n",
    "#             metrics_t[Y_PRED],\n",
    "#             epoch_ndx\n",
    "#         )\n",
    "\n",
    "#         bins = [x/50.0 for x in range(51)]\n",
    "\n",
    "#         negHist_mask = negLabel_mask & (metrics_t[Y_PRED] > 0.01)\n",
    "#         posHist_mask = posLabel_mask & (metrics_t[Y_PRED] < 0.99)\n",
    "\n",
    "#         if negHist_mask.any():\n",
    "#             writer.add_histogram(\n",
    "#                 'is_neg',\n",
    "#                 metrics_t[Y_PRED, negHist_mask],\n",
    "#                 epoch_ndx,\n",
    "#                 bins=bins, # type: ignore\n",
    "#             )\n",
    "#         if posHist_mask.any():\n",
    "#             writer.add_histogram(\n",
    "#                 'is_pos',\n",
    "#                 metrics_t[Y_PRED, posHist_mask],\n",
    "#                 epoch_ndx,\n",
    "#                 bins=bins, # type: ignore\n",
    "#             )\n",
    "            \n",
    "# def build_training_loop():\n",
    "#     unzipped_path = 'D:/LIDC-IDRI_unzipped'\n",
    "#     model = LunaModel()\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "#     loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "#     batch_size = 64\n",
    "#     num_workers = 4\n",
    "#     # dataset = LunaDataset()\n",
    "#     trainset = LunaDataset_Train()\n",
    "#     valset = LunaDataset_Val()\n",
    "#     # dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "#     train_loader = DataLoader(trainset, batch_size=batch_size, num_workers=num_workers)\n",
    "#     val_loader = DataLoader(valset, batch_size=batch_size, num_workers=num_workers)\n",
    "#     return TrainingLoop(model, optimizer, loss_fn, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/25 16:16:34 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 1 ----/609, starting\n",
      "2024/04/25 16:16:54 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 1    4/609, done at 2024-04-25 16:56:26, 0:39:51\n",
      "2024/04/25 16:16:57 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 1   16/609, done at 2024-04-25 16:30:19, 0:13:44\n",
      "2024/04/25 16:17:11 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 1   64/609, done at 2024-04-25 16:22:17, 0:05:42\n",
      "2024/04/25 16:18:05 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 1  256/609, done at 2024-04-25 16:20:10, 0:03:35\n",
      "2024/04/25 16:19:46 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 1 ----/609, done at 2024-04-25 16:19:46\n",
      "2024/04/25 16:19:46 INFO     TrainingLoop:096:logMetrics E1 TrainingLoop\n",
      "2024/04/25 16:19:46 INFO     TrainingLoop:138:logMetrics E1 trn      0.6629 loss,  61.5% accuracy, 0.5207 recall, 0.6417 precision, 0.5749 f1_score\n",
      "2024/04/25 16:19:46 INFO     TrainingLoop:150:logMetrics E1 trn_neg  0.6682 loss,  70.9% correct (13802 of 19460)\n",
      "2024/04/25 16:19:46 INFO     TrainingLoop:161:logMetrics E1 trn_pos  0.6576 loss,  52.1% correct (10134 of 19461)\n",
      "2024/04/25 16:19:46 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 1 ----/261, starting\n",
      "2024/04/25 16:20:01 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 1    4/261, done at 2024-04-25 16:32:28, 0:12:41\n",
      "2024/04/25 16:20:02 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 1   16/261, done at 2024-04-25 16:23:46, 0:04:00\n",
      "2024/04/25 16:20:06 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 1   64/261, done at 2024-04-25 16:21:06, 0:01:19\n",
      "2024/04/25 16:20:23 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 1  256/261, done at 2024-04-25 16:20:24, 0:00:37\n",
      "2024/04/25 16:20:24 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 1 ----/261, done at 2024-04-25 16:20:24\n",
      "2024/04/25 16:20:24 INFO     TrainingLoop:096:logMetrics E1 TrainingLoop\n",
      "2024/04/25 16:20:24 INFO     TrainingLoop:138:logMetrics E1 val      0.5901 loss,  74.3% accuracy, 0.5588 recall, 0.0044 precision, 0.0088 f1_score\n",
      "2024/04/25 16:20:24 INFO     TrainingLoop:150:logMetrics E1 val_neg  0.5899 loss,  74.4% correct (12384 of 16648)\n",
      "2024/04/25 16:20:24 INFO     TrainingLoop:161:logMetrics E1 val_pos  0.6824 loss,  55.9% correct (19 of 34)\n",
      "2024/04/25 16:20:24 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 2 ----/609, starting\n",
      "2024/04/25 16:20:40 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 2    4/609, done at 2024-04-25 16:53:12, 0:32:47\n",
      "2024/04/25 16:20:44 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 2   16/609, done at 2024-04-25 16:32:05, 0:11:41\n",
      "2024/04/25 16:20:57 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 2   64/609, done at 2024-04-25 16:25:36, 0:05:11\n",
      "2024/04/25 16:21:52 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 2  256/609, done at 2024-04-25 16:23:53, 0:03:28\n",
      "2024/04/25 16:23:33 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 2 ----/609, done at 2024-04-25 16:23:33\n",
      "2024/04/25 16:23:33 INFO     TrainingLoop:096:logMetrics E2 TrainingLoop\n",
      "2024/04/25 16:23:33 INFO     TrainingLoop:138:logMetrics E2 trn      0.5746 loss,  69.4% accuracy, 0.6449 recall, 0.7152 precision, 0.6783 f1_score\n",
      "2024/04/25 16:23:33 INFO     TrainingLoop:150:logMetrics E2 trn_neg  0.5713 loss,  74.3% correct (14463 of 19460)\n",
      "2024/04/25 16:23:33 INFO     TrainingLoop:161:logMetrics E2 trn_pos  0.5778 loss,  64.5% correct (12551 of 19461)\n",
      "2024/04/25 16:23:33 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 2 ----/261, starting\n",
      "2024/04/25 16:23:48 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 2    4/261, done at 2024-04-25 16:36:12, 0:12:38\n",
      "2024/04/25 16:23:49 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 2   16/261, done at 2024-04-25 16:27:33, 0:03:59\n",
      "2024/04/25 16:23:53 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 2   64/261, done at 2024-04-25 16:24:53, 0:01:19\n",
      "2024/04/25 16:24:10 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 2  256/261, done at 2024-04-25 16:24:11, 0:00:37\n",
      "2024/04/25 16:24:11 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 2 ----/261, done at 2024-04-25 16:24:11\n",
      "2024/04/25 16:24:11 INFO     TrainingLoop:096:logMetrics E2 TrainingLoop\n",
      "2024/04/25 16:24:11 INFO     TrainingLoop:138:logMetrics E2 val      0.4194 loss,  81.9% accuracy, 0.5588 recall, 0.0063 precision, 0.0124 f1_score\n",
      "2024/04/25 16:24:11 INFO     TrainingLoop:150:logMetrics E2 val_neg  0.4189 loss,  82.0% correct (13644 of 16648)\n",
      "2024/04/25 16:24:11 INFO     TrainingLoop:161:logMetrics E2 val_pos  0.6444 loss,  55.9% correct (19 of 34)\n",
      "2024/04/25 16:24:11 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 3 ----/609, starting\n",
      "2024/04/25 16:24:27 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 3    4/609, done at 2024-04-25 16:56:15, 0:32:03\n",
      "2024/04/25 16:24:30 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 3   16/609, done at 2024-04-25 16:35:39, 0:11:28\n",
      "2024/04/25 16:24:44 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 3   64/609, done at 2024-04-25 16:29:20, 0:05:08\n",
      "2024/04/25 16:25:39 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 3  256/609, done at 2024-04-25 16:27:39, 0:03:28\n",
      "2024/04/25 16:27:20 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 3 ----/609, done at 2024-04-25 16:27:20\n",
      "2024/04/25 16:27:20 INFO     TrainingLoop:096:logMetrics E3 TrainingLoop\n",
      "2024/04/25 16:27:20 INFO     TrainingLoop:138:logMetrics E3 trn      0.5050 loss,  74.8% accuracy, 0.7219 recall, 0.7615 precision, 0.7412 f1_score\n",
      "2024/04/25 16:27:20 INFO     TrainingLoop:150:logMetrics E3 trn_neg  0.5026 loss,  77.4% correct (15061 of 19460)\n",
      "2024/04/25 16:27:20 INFO     TrainingLoop:161:logMetrics E3 trn_pos  0.5075 loss,  72.2% correct (14048 of 19461)\n",
      "2024/04/25 16:27:20 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 3 ----/261, starting\n",
      "2024/04/25 16:27:34 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 3    4/261, done at 2024-04-25 16:39:46, 0:12:25\n",
      "2024/04/25 16:27:36 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 3   16/261, done at 2024-04-25 16:31:16, 0:03:55\n",
      "2024/04/25 16:27:40 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 3   64/261, done at 2024-04-25 16:28:39, 0:01:18\n",
      "2024/04/25 16:27:57 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 3  256/261, done at 2024-04-25 16:27:57, 0:00:37\n",
      "2024/04/25 16:27:58 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 3 ----/261, done at 2024-04-25 16:27:58\n",
      "2024/04/25 16:27:58 INFO     TrainingLoop:096:logMetrics E3 TrainingLoop\n",
      "2024/04/25 16:27:58 INFO     TrainingLoop:138:logMetrics E3 val      0.3258 loss,  88.0% accuracy, 0.7059 recall, 0.0119 precision, 0.0234 f1_score\n",
      "2024/04/25 16:27:58 INFO     TrainingLoop:150:logMetrics E3 val_neg  0.3252 loss,  88.0% correct (14654 of 16648)\n",
      "2024/04/25 16:27:58 INFO     TrainingLoop:161:logMetrics E3 val_pos  0.6074 loss,  70.6% correct (24 of 34)\n",
      "2024/04/25 16:27:58 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 4 ----/609, starting\n",
      "2024/04/25 16:28:13 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 4    4/609, done at 2024-04-25 16:59:29, 0:31:30\n",
      "2024/04/25 16:28:17 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 4   16/609, done at 2024-04-25 16:39:16, 0:11:18\n",
      "2024/04/25 16:28:30 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 4   64/609, done at 2024-04-25 16:33:03, 0:05:05\n",
      "2024/04/25 16:29:25 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 4  256/609, done at 2024-04-25 16:31:25, 0:03:27\n",
      "2024/04/25 16:31:07 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 4 ----/609, done at 2024-04-25 16:31:07\n",
      "2024/04/25 16:31:07 INFO     TrainingLoop:096:logMetrics E4 TrainingLoop\n",
      "2024/04/25 16:31:07 INFO     TrainingLoop:138:logMetrics E4 trn      0.4463 loss,  78.6% accuracy, 0.7699 recall, 0.7958 precision, 0.7826 f1_score\n",
      "2024/04/25 16:31:07 INFO     TrainingLoop:150:logMetrics E4 trn_neg  0.4445 loss,  80.2% correct (15616 of 19460)\n",
      "2024/04/25 16:31:07 INFO     TrainingLoop:161:logMetrics E4 trn_pos  0.4480 loss,  77.0% correct (14983 of 19461)\n",
      "2024/04/25 16:31:07 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 4 ----/261, starting\n",
      "2024/04/25 16:31:21 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 4    4/261, done at 2024-04-25 16:43:44, 0:12:37\n",
      "2024/04/25 16:31:22 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 4   16/261, done at 2024-04-25 16:35:06, 0:03:59\n",
      "2024/04/25 16:31:26 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 4   64/261, done at 2024-04-25 16:32:26, 0:01:19\n",
      "2024/04/25 16:31:43 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 4  256/261, done at 2024-04-25 16:31:44, 0:00:37\n",
      "2024/04/25 16:31:44 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 4 ----/261, done at 2024-04-25 16:31:44\n",
      "2024/04/25 16:31:44 INFO     TrainingLoop:096:logMetrics E4 TrainingLoop\n",
      "2024/04/25 16:31:44 INFO     TrainingLoop:138:logMetrics E4 val      0.5974 loss,  71.0% accuracy, 0.9412 recall, 0.0066 precision, 0.0130 f1_score\n",
      "2024/04/25 16:31:44 INFO     TrainingLoop:150:logMetrics E4 val_neg  0.5981 loss,  70.9% correct (11808 of 16648)\n",
      "2024/04/25 16:31:44 INFO     TrainingLoop:161:logMetrics E4 val_pos  0.2560 loss,  94.1% correct (32 of 34)\n",
      "2024/04/25 16:31:44 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 5 ----/609, starting\n",
      "2024/04/25 16:32:00 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 5    4/609, done at 2024-04-25 17:04:22, 0:32:37\n",
      "2024/04/25 16:32:04 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 5   16/609, done at 2024-04-25 16:43:23, 0:11:38\n",
      "2024/04/25 16:32:18 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 5   64/609, done at 2024-04-25 16:36:55, 0:05:10\n",
      "2024/04/25 16:33:13 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 5  256/609, done at 2024-04-25 16:35:13, 0:03:28\n",
      "2024/04/25 16:34:54 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 5 ----/609, done at 2024-04-25 16:34:54\n",
      "2024/04/25 16:34:54 INFO     TrainingLoop:096:logMetrics E5 TrainingLoop\n",
      "2024/04/25 16:34:54 INFO     TrainingLoop:138:logMetrics E5 trn      0.3960 loss,  81.8% accuracy, 0.8079 recall, 0.8239 precision, 0.8158 f1_score\n",
      "2024/04/25 16:34:54 INFO     TrainingLoop:150:logMetrics E5 trn_neg  0.3944 loss,  82.7% correct (16100 of 19460)\n",
      "2024/04/25 16:34:54 INFO     TrainingLoop:161:logMetrics E5 trn_pos  0.3977 loss,  80.8% correct (15722 of 19461)\n",
      "2024/04/25 16:34:54 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 5 ----/261, starting\n",
      "2024/04/25 16:35:09 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 5    4/261, done at 2024-04-25 16:47:35, 0:12:40\n",
      "2024/04/25 16:35:10 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 5   16/261, done at 2024-04-25 16:38:54, 0:04:00\n",
      "2024/04/25 16:35:14 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 5   64/261, done at 2024-04-25 16:36:14, 0:01:19\n",
      "2024/04/25 16:35:31 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 5  256/261, done at 2024-04-25 16:35:31, 0:00:37\n",
      "2024/04/25 16:35:32 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 5 ----/261, done at 2024-04-25 16:35:32\n",
      "2024/04/25 16:35:32 INFO     TrainingLoop:096:logMetrics E5 TrainingLoop\n",
      "2024/04/25 16:35:32 INFO     TrainingLoop:138:logMetrics E5 val      0.5338 loss,  74.8% accuracy, 0.8824 recall, 0.0071 precision, 0.0141 f1_score\n",
      "2024/04/25 16:35:32 INFO     TrainingLoop:150:logMetrics E5 val_neg  0.5344 loss,  74.8% correct (12454 of 16648)\n",
      "2024/04/25 16:35:32 INFO     TrainingLoop:161:logMetrics E5 val_pos  0.2498 loss,  88.2% correct (30 of 34)\n",
      "2024/04/25 16:35:32 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 6 ----/609, starting\n",
      "2024/04/25 16:35:48 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 6    4/609, done at 2024-04-25 17:07:39, 0:32:07\n",
      "2024/04/25 16:35:51 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 6   16/609, done at 2024-04-25 16:47:01, 0:11:29\n",
      "2024/04/25 16:36:05 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 6   64/609, done at 2024-04-25 16:40:41, 0:05:08\n",
      "2024/04/25 16:37:00 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 6  256/609, done at 2024-04-25 16:39:00, 0:03:28\n",
      "2024/04/25 16:38:41 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 6 ----/609, done at 2024-04-25 16:38:41\n",
      "2024/04/25 16:38:41 INFO     TrainingLoop:096:logMetrics E6 TrainingLoop\n",
      "2024/04/25 16:38:41 INFO     TrainingLoop:138:logMetrics E6 trn      0.3539 loss,  84.2% accuracy, 0.8351 recall, 0.8469 precision, 0.8410 f1_score\n",
      "2024/04/25 16:38:41 INFO     TrainingLoop:150:logMetrics E6 trn_neg  0.3534 loss,  84.9% correct (16523 of 19460)\n",
      "2024/04/25 16:38:41 INFO     TrainingLoop:161:logMetrics E6 trn_pos  0.3543 loss,  83.5% correct (16251 of 19461)\n",
      "2024/04/25 16:38:41 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 6 ----/261, starting\n",
      "2024/04/25 16:38:56 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 6    4/261, done at 2024-04-25 16:51:25, 0:12:43\n",
      "2024/04/25 16:38:57 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 6   16/261, done at 2024-04-25 16:42:42, 0:04:01\n",
      "2024/04/25 16:39:01 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 6   64/261, done at 2024-04-25 16:40:01, 0:01:20\n",
      "2024/04/25 16:39:18 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 6  256/261, done at 2024-04-25 16:39:19, 0:00:37\n",
      "2024/04/25 16:39:19 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 6 ----/261, done at 2024-04-25 16:39:19\n",
      "2024/04/25 16:39:19 INFO     TrainingLoop:096:logMetrics E6 TrainingLoop\n",
      "2024/04/25 16:39:19 INFO     TrainingLoop:138:logMetrics E6 val      0.2357 loss,  90.9% accuracy, 0.8824 recall, 0.0194 precision, 0.0379 f1_score\n",
      "2024/04/25 16:39:19 INFO     TrainingLoop:150:logMetrics E6 val_neg  0.2354 loss,  90.9% correct (15128 of 16648)\n",
      "2024/04/25 16:39:19 INFO     TrainingLoop:161:logMetrics E6 val_pos  0.3612 loss,  88.2% correct (30 of 34)\n",
      "2024/04/25 16:39:19 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 7 ----/609, starting\n",
      "2024/04/25 16:39:35 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 7    4/609, done at 2024-04-25 17:11:13, 0:31:53\n",
      "2024/04/25 16:39:38 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 7   16/609, done at 2024-04-25 16:50:45, 0:11:25\n",
      "2024/04/25 16:39:52 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 7   64/609, done at 2024-04-25 16:44:27, 0:05:07\n",
      "2024/04/25 16:40:47 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 7  256/609, done at 2024-04-25 16:42:47, 0:03:28\n",
      "2024/04/25 16:42:29 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 7 ----/609, done at 2024-04-25 16:42:29\n",
      "2024/04/25 16:42:29 INFO     TrainingLoop:096:logMetrics E7 TrainingLoop\n",
      "2024/04/25 16:42:29 INFO     TrainingLoop:138:logMetrics E7 trn      0.3159 loss,  86.2% accuracy, 0.8552 recall, 0.8675 precision, 0.8613 f1_score\n",
      "2024/04/25 16:42:29 INFO     TrainingLoop:150:logMetrics E7 trn_neg  0.3135 loss,  86.9% correct (16917 of 19460)\n",
      "2024/04/25 16:42:29 INFO     TrainingLoop:161:logMetrics E7 trn_pos  0.3182 loss,  85.5% correct (16644 of 19461)\n",
      "2024/04/25 16:42:29 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 7 ----/261, starting\n",
      "2024/04/25 16:42:44 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 7    4/261, done at 2024-04-25 16:55:23, 0:12:54\n",
      "2024/04/25 16:42:45 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 7   16/261, done at 2024-04-25 16:46:33, 0:04:04\n",
      "2024/04/25 16:42:49 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 7   64/261, done at 2024-04-25 16:43:50, 0:01:21\n",
      "2024/04/25 16:43:06 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 7  256/261, done at 2024-04-25 16:43:07, 0:00:37\n",
      "2024/04/25 16:43:07 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 7 ----/261, done at 2024-04-25 16:43:07\n",
      "2024/04/25 16:43:07 INFO     TrainingLoop:096:logMetrics E7 TrainingLoop\n",
      "2024/04/25 16:43:07 INFO     TrainingLoop:138:logMetrics E7 val      0.2862 loss,  88.1% accuracy, 0.9412 recall, 0.0159 precision, 0.0312 f1_score\n",
      "2024/04/25 16:43:07 INFO     TrainingLoop:150:logMetrics E7 val_neg  0.2862 loss,  88.1% correct (14663 of 16648)\n",
      "2024/04/25 16:43:07 INFO     TrainingLoop:161:logMetrics E7 val_pos  0.2578 loss,  94.1% correct (32 of 34)\n",
      "2024/04/25 16:43:07 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 8 ----/609, starting\n",
      "2024/04/25 16:43:23 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 8    4/609, done at 2024-04-25 17:15:09, 0:32:02\n",
      "2024/04/25 16:43:26 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 8   16/609, done at 2024-04-25 16:54:35, 0:11:28\n",
      "2024/04/25 16:43:40 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 8   64/609, done at 2024-04-25 16:48:15, 0:05:08\n",
      "2024/04/25 16:44:35 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 8  256/609, done at 2024-04-25 16:46:35, 0:03:28\n",
      "2024/04/25 16:46:16 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 8 ----/609, done at 2024-04-25 16:46:16\n",
      "2024/04/25 16:46:16 INFO     TrainingLoop:096:logMetrics E8 TrainingLoop\n",
      "2024/04/25 16:46:16 INFO     TrainingLoop:138:logMetrics E8 trn      0.2971 loss,  87.3% accuracy, 0.8680 recall, 0.8763 precision, 0.8721 f1_score\n",
      "2024/04/25 16:46:16 INFO     TrainingLoop:150:logMetrics E8 trn_neg  0.2956 loss,  87.7% correct (17075 of 19460)\n",
      "2024/04/25 16:46:16 INFO     TrainingLoop:161:logMetrics E8 trn_pos  0.2986 loss,  86.8% correct (16892 of 19461)\n",
      "2024/04/25 16:46:16 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 8 ----/261, starting\n",
      "2024/04/25 16:46:31 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 8    4/261, done at 2024-04-25 16:58:52, 0:12:35\n",
      "2024/04/25 16:46:32 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 8   16/261, done at 2024-04-25 16:50:15, 0:03:58\n",
      "2024/04/25 16:46:36 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 8   64/261, done at 2024-04-25 16:47:36, 0:01:19\n",
      "2024/04/25 16:46:53 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 8  256/261, done at 2024-04-25 16:46:54, 0:00:37\n",
      "2024/04/25 16:46:54 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 8 ----/261, done at 2024-04-25 16:46:54\n",
      "2024/04/25 16:46:54 INFO     TrainingLoop:096:logMetrics E8 TrainingLoop\n",
      "2024/04/25 16:46:54 INFO     TrainingLoop:138:logMetrics E8 val      0.2256 loss,  91.0% accuracy, 0.9412 recall, 0.0209 precision, 0.0410 f1_score\n",
      "2024/04/25 16:46:54 INFO     TrainingLoop:150:logMetrics E8 val_neg  0.2256 loss,  91.0% correct (15152 of 16648)\n",
      "2024/04/25 16:46:54 INFO     TrainingLoop:161:logMetrics E8 val_pos  0.2348 loss,  94.1% correct (32 of 34)\n",
      "2024/04/25 16:46:54 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 9 ----/609, starting\n",
      "2024/04/25 16:47:10 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 9    4/609, done at 2024-04-25 17:18:40, 0:31:45\n",
      "2024/04/25 16:47:13 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 9   16/609, done at 2024-04-25 16:58:17, 0:11:23\n",
      "2024/04/25 16:47:27 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 9   64/609, done at 2024-04-25 16:52:01, 0:05:07\n",
      "2024/04/25 16:48:22 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 9  256/609, done at 2024-04-25 16:50:22, 0:03:27\n",
      "2024/04/25 16:50:04 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 9 ----/609, done at 2024-04-25 16:50:04\n",
      "2024/04/25 16:50:04 INFO     TrainingLoop:096:logMetrics E9 TrainingLoop\n",
      "2024/04/25 16:50:04 INFO     TrainingLoop:138:logMetrics E9 trn      0.2702 loss,  88.6% accuracy, 0.8812 recall, 0.8902 precision, 0.8857 f1_score\n",
      "2024/04/25 16:50:04 INFO     TrainingLoop:150:logMetrics E9 trn_neg  0.2683 loss,  89.1% correct (17344 of 19460)\n",
      "2024/04/25 16:50:04 INFO     TrainingLoop:161:logMetrics E9 trn_pos  0.2722 loss,  88.1% correct (17149 of 19461)\n",
      "2024/04/25 16:50:04 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 9 ----/261, starting\n",
      "2024/04/25 16:50:18 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 9    4/261, done at 2024-04-25 17:02:35, 0:12:31\n",
      "2024/04/25 16:50:19 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 9   16/261, done at 2024-04-25 16:54:01, 0:03:57\n",
      "2024/04/25 16:50:23 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 9   64/261, done at 2024-04-25 16:51:23, 0:01:19\n",
      "2024/04/25 16:50:40 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 9  256/261, done at 2024-04-25 16:50:41, 0:00:37\n",
      "2024/04/25 16:50:41 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 9 ----/261, done at 2024-04-25 16:50:41\n",
      "2024/04/25 16:50:41 INFO     TrainingLoop:096:logMetrics E9 TrainingLoop\n",
      "2024/04/25 16:50:41 INFO     TrainingLoop:138:logMetrics E9 val      0.1770 loss,  93.5% accuracy, 0.9118 recall, 0.0279 precision, 0.0541 f1_score\n",
      "2024/04/25 16:50:41 INFO     TrainingLoop:150:logMetrics E9 val_neg  0.1768 loss,  93.5% correct (15566 of 16648)\n",
      "2024/04/25 16:50:41 INFO     TrainingLoop:161:logMetrics E9 val_pos  0.2435 loss,  91.2% correct (31 of 34)\n",
      "2024/04/25 16:50:41 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 10 ----/609, starting\n",
      "2024/04/25 16:50:57 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 10    4/609, done at 2024-04-25 17:22:36, 0:31:54\n",
      "2024/04/25 16:51:01 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 10   16/609, done at 2024-04-25 17:02:07, 0:11:25\n",
      "2024/04/25 16:51:14 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 10   64/609, done at 2024-04-25 16:55:49, 0:05:07\n",
      "2024/04/25 16:52:09 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 10  256/609, done at 2024-04-25 16:54:09, 0:03:28\n",
      "2024/04/25 16:53:51 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 10 ----/609, done at 2024-04-25 16:53:51\n",
      "2024/04/25 16:53:51 INFO     TrainingLoop:096:logMetrics E10 TrainingLoop\n",
      "2024/04/25 16:53:51 INFO     TrainingLoop:138:logMetrics E10 trn      0.2508 loss,  89.6% accuracy, 0.8917 recall, 0.8992 precision, 0.8955 f1_score\n",
      "2024/04/25 16:53:51 INFO     TrainingLoop:150:logMetrics E10 trn_neg  0.2481 loss,  90.0% correct (17515 of 19460)\n",
      "2024/04/25 16:53:51 INFO     TrainingLoop:161:logMetrics E10 trn_pos  0.2535 loss,  89.2% correct (17354 of 19461)\n",
      "2024/04/25 16:53:51 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 10 ----/261, starting\n",
      "2024/04/25 16:54:05 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 10    4/261, done at 2024-04-25 17:06:25, 0:12:34\n",
      "2024/04/25 16:54:06 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 10   16/261, done at 2024-04-25 16:57:49, 0:03:58\n",
      "2024/04/25 16:54:11 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 10   64/261, done at 2024-04-25 16:55:10, 0:01:19\n",
      "2024/04/25 16:54:28 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 10  256/261, done at 2024-04-25 16:54:28, 0:00:37\n",
      "2024/04/25 16:54:29 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 10 ----/261, done at 2024-04-25 16:54:29\n",
      "2024/04/25 16:54:29 INFO     TrainingLoop:096:logMetrics E10 TrainingLoop\n",
      "2024/04/25 16:54:29 INFO     TrainingLoop:138:logMetrics E10 val      0.2483 loss,  90.0% accuracy, 0.9412 recall, 0.0188 precision, 0.0369 f1_score\n",
      "2024/04/25 16:54:29 INFO     TrainingLoop:150:logMetrics E10 val_neg  0.2485 loss,  90.0% correct (14980 of 16648)\n",
      "2024/04/25 16:54:29 INFO     TrainingLoop:161:logMetrics E10 val_pos  0.1595 loss,  94.1% correct (32 of 34)\n",
      "2024/04/25 16:54:29 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 11 ----/609, starting\n",
      "2024/04/25 16:54:45 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 11    4/609, done at 2024-04-25 17:26:49, 0:32:20\n",
      "2024/04/25 16:54:48 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 11   16/609, done at 2024-04-25 17:06:02, 0:11:33\n",
      "2024/04/25 16:55:02 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 11   64/609, done at 2024-04-25 16:59:38, 0:05:09\n",
      "2024/04/25 16:55:57 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 11  256/609, done at 2024-04-25 16:57:57, 0:03:28\n",
      "2024/04/25 16:57:38 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 11 ----/609, done at 2024-04-25 16:57:38\n",
      "2024/04/25 16:57:38 INFO     TrainingLoop:096:logMetrics E11 TrainingLoop\n",
      "2024/04/25 16:57:38 INFO     TrainingLoop:138:logMetrics E11 trn      0.2354 loss,  90.2% accuracy, 0.8987 recall, 0.9054 precision, 0.9021 f1_score\n",
      "2024/04/25 16:57:38 INFO     TrainingLoop:150:logMetrics E11 trn_neg  0.2323 loss,  90.6% correct (17633 of 19460)\n",
      "2024/04/25 16:57:38 INFO     TrainingLoop:161:logMetrics E11 trn_pos  0.2385 loss,  89.9% correct (17490 of 19461)\n",
      "2024/04/25 16:57:38 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 11 ----/261, starting\n",
      "2024/04/25 16:57:53 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 11    4/261, done at 2024-04-25 17:10:09, 0:12:30\n",
      "2024/04/25 16:57:54 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 11   16/261, done at 2024-04-25 17:01:35, 0:03:57\n",
      "2024/04/25 16:57:58 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 11   64/261, done at 2024-04-25 16:58:57, 0:01:19\n",
      "2024/04/25 16:58:15 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 11  256/261, done at 2024-04-25 16:58:16, 0:00:37\n",
      "2024/04/25 16:58:16 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 11 ----/261, done at 2024-04-25 16:58:16\n",
      "2024/04/25 16:58:16 INFO     TrainingLoop:096:logMetrics E11 TrainingLoop\n",
      "2024/04/25 16:58:16 INFO     TrainingLoop:138:logMetrics E11 val      0.2467 loss,  90.1% accuracy, 0.9412 recall, 0.0191 precision, 0.0374 f1_score\n",
      "2024/04/25 16:58:16 INFO     TrainingLoop:150:logMetrics E11 val_neg  0.2468 loss,  90.1% correct (15005 of 16648)\n",
      "2024/04/25 16:58:16 INFO     TrainingLoop:161:logMetrics E11 val_pos  0.2028 loss,  94.1% correct (32 of 34)\n",
      "2024/04/25 16:58:16 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 12 ----/609, starting\n",
      "2024/04/25 16:58:32 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 12    4/609, done at 2024-04-25 17:30:02, 0:31:45\n",
      "2024/04/25 16:58:35 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 12   16/609, done at 2024-04-25 17:09:39, 0:11:23\n",
      "2024/04/25 16:58:49 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 12   64/609, done at 2024-04-25 17:03:23, 0:05:07\n",
      "2024/04/25 16:59:44 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 12  256/609, done at 2024-04-25 17:01:44, 0:03:27\n",
      "2024/04/25 17:01:25 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 12 ----/609, done at 2024-04-25 17:01:25\n",
      "2024/04/25 17:01:25 INFO     TrainingLoop:096:logMetrics E12 TrainingLoop\n",
      "2024/04/25 17:01:25 INFO     TrainingLoop:138:logMetrics E12 trn      0.2225 loss,  90.9% accuracy, 0.9048 recall, 0.9124 precision, 0.9086 f1_score\n",
      "2024/04/25 17:01:25 INFO     TrainingLoop:150:logMetrics E12 trn_neg  0.2224 loss,  91.3% correct (17770 of 19460)\n",
      "2024/04/25 17:01:25 INFO     TrainingLoop:161:logMetrics E12 trn_pos  0.2226 loss,  90.5% correct (17609 of 19461)\n",
      "2024/04/25 17:01:25 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 12 ----/261, starting\n",
      "2024/04/25 17:01:40 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 12    4/261, done at 2024-04-25 17:14:19, 0:12:53\n",
      "2024/04/25 17:01:41 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 12   16/261, done at 2024-04-25 17:05:29, 0:04:03\n",
      "2024/04/25 17:01:46 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 12   64/261, done at 2024-04-25 17:02:46, 0:01:20\n",
      "2024/04/25 17:02:03 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 12  256/261, done at 2024-04-25 17:02:03, 0:00:37\n",
      "2024/04/25 17:02:03 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 12 ----/261, done at 2024-04-25 17:02:03\n",
      "2024/04/25 17:02:03 INFO     TrainingLoop:096:logMetrics E12 TrainingLoop\n",
      "2024/04/25 17:02:03 INFO     TrainingLoop:138:logMetrics E12 val      0.6817 loss,  71.7% accuracy, 0.9706 recall, 0.0069 precision, 0.0138 f1_score\n",
      "2024/04/25 17:02:03 INFO     TrainingLoop:150:logMetrics E12 val_neg  0.6830 loss,  71.6% correct (11924 of 16648)\n",
      "2024/04/25 17:02:03 INFO     TrainingLoop:161:logMetrics E12 val_pos  0.0824 loss,  97.1% correct (33 of 34)\n",
      "2024/04/25 17:02:03 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 13 ----/609, starting\n",
      "2024/04/25 17:02:19 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 13    4/609, done at 2024-04-25 17:33:53, 0:31:49\n",
      "2024/04/25 17:02:23 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 13   16/609, done at 2024-04-25 17:13:28, 0:11:24\n",
      "2024/04/25 17:02:36 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 13   64/609, done at 2024-04-25 17:07:11, 0:05:07\n",
      "2024/04/25 17:03:31 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 13  256/609, done at 2024-04-25 17:05:32, 0:03:28\n",
      "2024/04/25 17:05:13 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 13 ----/609, done at 2024-04-25 17:05:13\n",
      "2024/04/25 17:05:13 INFO     TrainingLoop:096:logMetrics E13 TrainingLoop\n",
      "2024/04/25 17:05:13 INFO     TrainingLoop:138:logMetrics E13 trn      0.2176 loss,  91.2% accuracy, 0.9093 recall, 0.9144 precision, 0.9119 f1_score\n",
      "2024/04/25 17:05:13 INFO     TrainingLoop:150:logMetrics E13 trn_neg  0.2182 loss,  91.5% correct (17804 of 19460)\n",
      "2024/04/25 17:05:13 INFO     TrainingLoop:161:logMetrics E13 trn_pos  0.2171 loss,  90.9% correct (17696 of 19461)\n",
      "2024/04/25 17:05:13 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 13 ----/261, starting\n",
      "2024/04/25 17:05:27 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 13    4/261, done at 2024-04-25 17:17:47, 0:12:34\n",
      "2024/04/25 17:05:28 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 13   16/261, done at 2024-04-25 17:09:11, 0:03:58\n",
      "2024/04/25 17:05:33 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 13   64/261, done at 2024-04-25 17:06:32, 0:01:19\n",
      "2024/04/25 17:05:50 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 13  256/261, done at 2024-04-25 17:05:50, 0:00:37\n",
      "2024/04/25 17:05:51 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 13 ----/261, done at 2024-04-25 17:05:51\n",
      "2024/04/25 17:05:51 INFO     TrainingLoop:096:logMetrics E13 TrainingLoop\n",
      "2024/04/25 17:05:51 INFO     TrainingLoop:138:logMetrics E13 val      0.1870 loss,  92.7% accuracy, 0.9706 recall, 0.0263 precision, 0.0512 f1_score\n",
      "2024/04/25 17:05:51 INFO     TrainingLoop:150:logMetrics E13 val_neg  0.1871 loss,  92.7% correct (15425 of 16648)\n",
      "2024/04/25 17:05:51 INFO     TrainingLoop:161:logMetrics E13 val_pos  0.1168 loss,  97.1% correct (33 of 34)\n",
      "2024/04/25 17:05:51 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 14 ----/609, starting\n",
      "2024/04/25 17:06:06 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 14    4/609, done at 2024-04-25 17:37:38, 0:31:47\n",
      "2024/04/25 17:06:10 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 14   16/609, done at 2024-04-25 17:17:14, 0:11:23\n",
      "2024/04/25 17:06:23 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 14   64/609, done at 2024-04-25 17:10:58, 0:05:07\n",
      "2024/04/25 17:07:18 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 14  256/609, done at 2024-04-25 17:09:19, 0:03:28\n",
      "2024/04/25 17:09:00 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 14 ----/609, done at 2024-04-25 17:09:00\n",
      "2024/04/25 17:09:00 INFO     TrainingLoop:096:logMetrics E14 TrainingLoop\n",
      "2024/04/25 17:09:00 INFO     TrainingLoop:138:logMetrics E14 trn      0.2036 loss,  92.0% accuracy, 0.9148 recall, 0.9238 precision, 0.9192 f1_score\n",
      "2024/04/25 17:09:00 INFO     TrainingLoop:150:logMetrics E14 trn_neg  0.2015 loss,  92.5% correct (17991 of 19460)\n",
      "2024/04/25 17:09:00 INFO     TrainingLoop:161:logMetrics E14 trn_pos  0.2056 loss,  91.5% correct (17802 of 19461)\n",
      "2024/04/25 17:09:00 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 14 ----/261, starting\n",
      "2024/04/25 17:09:14 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 14    4/261, done at 2024-04-25 17:21:33, 0:12:32\n",
      "2024/04/25 17:09:16 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 14   16/261, done at 2024-04-25 17:12:58, 0:03:57\n",
      "2024/04/25 17:09:20 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 14   64/261, done at 2024-04-25 17:10:19, 0:01:19\n",
      "2024/04/25 17:09:37 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 14  256/261, done at 2024-04-25 17:09:37, 0:00:37\n",
      "2024/04/25 17:09:38 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 14 ----/261, done at 2024-04-25 17:09:38\n",
      "2024/04/25 17:09:38 INFO     TrainingLoop:096:logMetrics E14 TrainingLoop\n",
      "2024/04/25 17:09:38 INFO     TrainingLoop:138:logMetrics E14 val      0.1320 loss,  95.0% accuracy, 0.9706 recall, 0.0382 precision, 0.0736 f1_score\n",
      "2024/04/25 17:09:38 INFO     TrainingLoop:150:logMetrics E14 val_neg  0.1319 loss,  95.0% correct (15818 of 16648)\n",
      "2024/04/25 17:09:38 INFO     TrainingLoop:161:logMetrics E14 val_pos  0.1569 loss,  97.1% correct (33 of 34)\n",
      "2024/04/25 17:09:38 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 15 ----/609, starting\n",
      "2024/04/25 17:09:54 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 15    4/609, done at 2024-04-25 17:41:41, 0:32:02\n",
      "2024/04/25 17:09:57 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 15   16/609, done at 2024-04-25 17:21:06, 0:11:28\n",
      "2024/04/25 17:10:11 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 15   64/609, done at 2024-04-25 17:14:46, 0:05:08\n",
      "2024/04/25 17:11:06 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 15  256/609, done at 2024-04-25 17:13:06, 0:03:28\n",
      "2024/04/25 17:12:47 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 15 ----/609, done at 2024-04-25 17:12:47\n",
      "2024/04/25 17:12:47 INFO     TrainingLoop:096:logMetrics E15 TrainingLoop\n",
      "2024/04/25 17:12:47 INFO     TrainingLoop:138:logMetrics E15 trn      0.1916 loss,  92.5% accuracy, 0.9217 recall, 0.9273 precision, 0.9245 f1_score\n",
      "2024/04/25 17:12:47 INFO     TrainingLoop:150:logMetrics E15 trn_neg  0.1905 loss,  92.8% correct (18053 of 19460)\n",
      "2024/04/25 17:12:47 INFO     TrainingLoop:161:logMetrics E15 trn_pos  0.1928 loss,  92.2% correct (17938 of 19461)\n",
      "2024/04/25 17:12:47 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 15 ----/261, starting\n",
      "2024/04/25 17:13:02 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 15    4/261, done at 2024-04-25 17:25:21, 0:12:33\n",
      "2024/04/25 17:13:03 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 15   16/261, done at 2024-04-25 17:16:45, 0:03:58\n",
      "2024/04/25 17:13:07 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 15   64/261, done at 2024-04-25 17:14:07, 0:01:19\n",
      "2024/04/25 17:13:24 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 15  256/261, done at 2024-04-25 17:13:25, 0:00:37\n",
      "2024/04/25 17:13:25 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 15 ----/261, done at 2024-04-25 17:13:25\n",
      "2024/04/25 17:13:25 INFO     TrainingLoop:096:logMetrics E15 TrainingLoop\n",
      "2024/04/25 17:13:25 INFO     TrainingLoop:138:logMetrics E15 val      0.1889 loss,  92.8% accuracy, 0.9706 recall, 0.0267 precision, 0.0521 f1_score\n",
      "2024/04/25 17:13:25 INFO     TrainingLoop:150:logMetrics E15 val_neg  0.1890 loss,  92.8% correct (15447 of 16648)\n",
      "2024/04/25 17:13:25 INFO     TrainingLoop:161:logMetrics E15 val_pos  0.1449 loss,  97.1% correct (33 of 34)\n",
      "2024/04/25 17:13:25 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 16 ----/609, starting\n",
      "2024/04/25 17:13:41 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 16    4/609, done at 2024-04-25 17:45:10, 0:31:45\n",
      "2024/04/25 17:13:44 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 16   16/609, done at 2024-04-25 17:24:48, 0:11:23\n",
      "2024/04/25 17:13:58 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 16   64/609, done at 2024-04-25 17:18:32, 0:05:06\n",
      "2024/04/25 17:14:53 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 16  256/609, done at 2024-04-25 17:16:53, 0:03:27\n",
      "2024/04/25 17:16:34 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 16 ----/609, done at 2024-04-25 17:16:34\n",
      "2024/04/25 17:16:34 INFO     TrainingLoop:096:logMetrics E16 TrainingLoop\n",
      "2024/04/25 17:16:34 INFO     TrainingLoop:138:logMetrics E16 trn      0.1874 loss,  92.6% accuracy, 0.9230 recall, 0.9287 precision, 0.9259 f1_score\n",
      "2024/04/25 17:16:34 INFO     TrainingLoop:150:logMetrics E16 trn_neg  0.1877 loss,  92.9% correct (18082 of 19460)\n",
      "2024/04/25 17:16:34 INFO     TrainingLoop:161:logMetrics E16 trn_pos  0.1872 loss,  92.3% correct (17962 of 19461)\n",
      "2024/04/25 17:16:35 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 16 ----/261, starting\n",
      "2024/04/25 17:16:49 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 16    4/261, done at 2024-04-25 17:29:16, 0:12:41\n",
      "2024/04/25 17:16:50 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 16   16/261, done at 2024-04-25 17:20:35, 0:04:00\n",
      "2024/04/25 17:16:54 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 16   64/261, done at 2024-04-25 17:17:54, 0:01:19\n",
      "2024/04/25 17:17:11 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 16  256/261, done at 2024-04-25 17:17:12, 0:00:37\n",
      "2024/04/25 17:17:12 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 16 ----/261, done at 2024-04-25 17:17:12\n",
      "2024/04/25 17:17:12 INFO     TrainingLoop:096:logMetrics E16 TrainingLoop\n",
      "2024/04/25 17:17:12 INFO     TrainingLoop:138:logMetrics E16 val      0.3534 loss,  85.3% accuracy, 0.9706 recall, 0.0133 precision, 0.0263 f1_score\n",
      "2024/04/25 17:17:12 INFO     TrainingLoop:150:logMetrics E16 val_neg  0.3540 loss,  85.3% correct (14205 of 16648)\n",
      "2024/04/25 17:17:12 INFO     TrainingLoop:161:logMetrics E16 val_pos  0.0421 loss,  97.1% correct (33 of 34)\n",
      "2024/04/25 17:17:12 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 17 ----/609, starting\n",
      "2024/04/25 17:17:28 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 17    4/609, done at 2024-04-25 17:49:04, 0:31:51\n",
      "2024/04/25 17:17:32 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 17   16/609, done at 2024-04-25 17:28:37, 0:11:24\n",
      "2024/04/25 17:17:45 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 17   64/609, done at 2024-04-25 17:22:20, 0:05:07\n",
      "2024/04/25 17:18:40 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 17  256/609, done at 2024-04-25 17:20:41, 0:03:28\n",
      "2024/04/25 17:20:22 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 17 ----/609, done at 2024-04-25 17:20:22\n",
      "2024/04/25 17:20:22 INFO     TrainingLoop:096:logMetrics E17 TrainingLoop\n",
      "2024/04/25 17:20:22 INFO     TrainingLoop:138:logMetrics E17 trn      0.1753 loss,  93.2% accuracy, 0.9308 recall, 0.9337 precision, 0.9322 f1_score\n",
      "2024/04/25 17:20:22 INFO     TrainingLoop:150:logMetrics E17 trn_neg  0.1755 loss,  93.4% correct (18173 of 19460)\n",
      "2024/04/25 17:20:22 INFO     TrainingLoop:161:logMetrics E17 trn_pos  0.1750 loss,  93.1% correct (18115 of 19461)\n",
      "2024/04/25 17:20:22 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 17 ----/261, starting\n",
      "2024/04/25 17:20:36 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 17    4/261, done at 2024-04-25 17:32:57, 0:12:35\n",
      "2024/04/25 17:20:37 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 17   16/261, done at 2024-04-25 17:24:20, 0:03:58\n",
      "2024/04/25 17:20:42 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 17   64/261, done at 2024-04-25 17:21:41, 0:01:19\n",
      "2024/04/25 17:20:59 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 17  256/261, done at 2024-04-25 17:20:59, 0:00:37\n",
      "2024/04/25 17:21:00 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 17 ----/261, done at 2024-04-25 17:21:00\n",
      "2024/04/25 17:21:00 INFO     TrainingLoop:096:logMetrics E17 TrainingLoop\n",
      "2024/04/25 17:21:00 INFO     TrainingLoop:138:logMetrics E17 val      0.1581 loss,  94.0% accuracy, 0.9706 recall, 0.0320 precision, 0.0620 f1_score\n",
      "2024/04/25 17:21:00 INFO     TrainingLoop:150:logMetrics E17 val_neg  0.1582 loss,  94.0% correct (15650 of 16648)\n",
      "2024/04/25 17:21:00 INFO     TrainingLoop:161:logMetrics E17 val_pos  0.1134 loss,  97.1% correct (33 of 34)\n",
      "2024/04/25 17:21:00 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 18 ----/609, starting\n",
      "2024/04/25 17:21:16 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 18    4/609, done at 2024-04-25 17:53:30, 0:32:30\n",
      "2024/04/25 17:21:19 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 18   16/609, done at 2024-04-25 17:32:36, 0:11:36\n",
      "2024/04/25 17:21:33 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 18   64/609, done at 2024-04-25 17:26:10, 0:05:10\n",
      "2024/04/25 17:22:28 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 18  256/609, done at 2024-04-25 17:24:29, 0:03:28\n",
      "2024/04/25 17:24:10 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 18 ----/609, done at 2024-04-25 17:24:10\n",
      "2024/04/25 17:24:10 INFO     TrainingLoop:096:logMetrics E18 TrainingLoop\n",
      "2024/04/25 17:24:10 INFO     TrainingLoop:138:logMetrics E18 trn      0.1652 loss,  93.6% accuracy, 0.9334 recall, 0.9383 precision, 0.9358 f1_score\n",
      "2024/04/25 17:24:10 INFO     TrainingLoop:150:logMetrics E18 trn_neg  0.1654 loss,  93.9% correct (18265 of 19460)\n",
      "2024/04/25 17:24:10 INFO     TrainingLoop:161:logMetrics E18 trn_pos  0.1649 loss,  93.3% correct (18164 of 19461)\n",
      "2024/04/25 17:24:10 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 18 ----/261, starting\n",
      "2024/04/25 17:24:24 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 18    4/261, done at 2024-04-25 17:36:44, 0:12:34\n",
      "2024/04/25 17:24:25 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 18   16/261, done at 2024-04-25 17:28:08, 0:03:58\n",
      "2024/04/25 17:24:29 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 18   64/261, done at 2024-04-25 17:25:29, 0:01:19\n",
      "2024/04/25 17:24:47 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 18  256/261, done at 2024-04-25 17:24:47, 0:00:37\n",
      "2024/04/25 17:24:47 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 18 ----/261, done at 2024-04-25 17:24:47\n",
      "2024/04/25 17:24:47 INFO     TrainingLoop:096:logMetrics E18 TrainingLoop\n",
      "2024/04/25 17:24:47 INFO     TrainingLoop:138:logMetrics E18 val      0.1684 loss,  93.5% accuracy, 0.9706 recall, 0.0295 precision, 0.0572 f1_score\n",
      "2024/04/25 17:24:47 INFO     TrainingLoop:150:logMetrics E18 val_neg  0.1686 loss,  93.5% correct (15562 of 16648)\n",
      "2024/04/25 17:24:47 INFO     TrainingLoop:161:logMetrics E18 val_pos  0.0592 loss,  97.1% correct (33 of 34)\n",
      "2024/04/25 17:24:47 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 19 ----/609, starting\n",
      "2024/04/25 17:25:03 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 19    4/609, done at 2024-04-25 17:56:38, 0:31:50\n",
      "2024/04/25 17:25:07 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 19   16/609, done at 2024-04-25 17:36:12, 0:11:24\n",
      "2024/04/25 17:25:20 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 19   64/609, done at 2024-04-25 17:29:55, 0:05:07\n",
      "2024/04/25 17:26:15 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 19  256/609, done at 2024-04-25 17:28:16, 0:03:28\n",
      "2024/04/25 17:27:57 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 19 ----/609, done at 2024-04-25 17:27:57\n",
      "2024/04/25 17:27:57 INFO     TrainingLoop:096:logMetrics E19 TrainingLoop\n",
      "2024/04/25 17:27:57 INFO     TrainingLoop:138:logMetrics E19 trn      0.1670 loss,  93.7% accuracy, 0.9332 recall, 0.9395 precision, 0.9363 f1_score\n",
      "2024/04/25 17:27:57 INFO     TrainingLoop:150:logMetrics E19 trn_neg  0.1650 loss,  94.0% correct (18290 of 19460)\n",
      "2024/04/25 17:27:57 INFO     TrainingLoop:161:logMetrics E19 trn_pos  0.1690 loss,  93.3% correct (18161 of 19461)\n",
      "2024/04/25 17:27:57 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 19 ----/261, starting\n",
      "2024/04/25 17:28:11 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 19    4/261, done at 2024-04-25 17:40:28, 0:12:31\n",
      "2024/04/25 17:28:12 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 19   16/261, done at 2024-04-25 17:31:54, 0:03:57\n",
      "2024/04/25 17:28:17 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 19   64/261, done at 2024-04-25 17:29:16, 0:01:19\n",
      "2024/04/25 17:28:34 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 19  256/261, done at 2024-04-25 17:28:34, 0:00:37\n",
      "2024/04/25 17:28:35 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 19 ----/261, done at 2024-04-25 17:28:35\n",
      "2024/04/25 17:28:35 INFO     TrainingLoop:096:logMetrics E19 TrainingLoop\n",
      "2024/04/25 17:28:35 INFO     TrainingLoop:138:logMetrics E19 val      0.1257 loss,  95.4% accuracy, 0.9706 recall, 0.0410 precision, 0.0788 f1_score\n",
      "2024/04/25 17:28:35 INFO     TrainingLoop:150:logMetrics E19 val_neg  0.1258 loss,  95.4% correct (15877 of 16648)\n",
      "2024/04/25 17:28:35 INFO     TrainingLoop:161:logMetrics E19 val_pos  0.0690 loss,  97.1% correct (33 of 34)\n",
      "2024/04/25 17:28:35 WARNING  utilG:044:enumerateWithEstimate EPOCH_train: 20 ----/609, starting\n",
      "2024/04/25 17:28:50 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 20    4/609, done at 2024-04-25 18:00:22, 0:31:47\n",
      "2024/04/25 17:28:54 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 20   16/609, done at 2024-04-25 17:39:59, 0:11:23\n",
      "2024/04/25 17:29:08 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 20   64/609, done at 2024-04-25 17:33:42, 0:05:07\n",
      "2024/04/25 17:30:03 INFO     utilG:061:enumerateWithEstimate EPOCH_train: 20  256/609, done at 2024-04-25 17:32:03, 0:03:28\n",
      "2024/04/25 17:31:44 WARNING  utilG:074:enumerateWithEstimate EPOCH_train: 20 ----/609, done at 2024-04-25 17:31:44\n",
      "2024/04/25 17:31:44 INFO     TrainingLoop:096:logMetrics E20 TrainingLoop\n",
      "2024/04/25 17:31:44 INFO     TrainingLoop:138:logMetrics E20 trn      0.1545 loss,  94.0% accuracy, 0.9378 recall, 0.9411 precision, 0.9395 f1_score\n",
      "2024/04/25 17:31:44 INFO     TrainingLoop:150:logMetrics E20 trn_neg  0.1540 loss,  94.1% correct (18318 of 19460)\n",
      "2024/04/25 17:31:44 INFO     TrainingLoop:161:logMetrics E20 trn_pos  0.1551 loss,  93.8% correct (18251 of 19461)\n",
      "2024/04/25 17:31:44 WARNING  utilG:044:enumerateWithEstimate EPOCH_val: 20 ----/261, starting\n",
      "2024/04/25 17:31:59 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 20    4/261, done at 2024-04-25 17:44:19, 0:12:35\n",
      "2024/04/25 17:32:00 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 20   16/261, done at 2024-04-25 17:35:43, 0:03:58\n",
      "2024/04/25 17:32:04 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 20   64/261, done at 2024-04-25 17:33:04, 0:01:19\n",
      "2024/04/25 17:32:21 INFO     utilG:061:enumerateWithEstimate EPOCH_val: 20  256/261, done at 2024-04-25 17:32:22, 0:00:37\n",
      "2024/04/25 17:32:22 WARNING  utilG:074:enumerateWithEstimate EPOCH_val: 20 ----/261, done at 2024-04-25 17:32:22\n",
      "2024/04/25 17:32:22 INFO     TrainingLoop:096:logMetrics E20 TrainingLoop\n",
      "2024/04/25 17:32:22 INFO     TrainingLoop:138:logMetrics E20 val      0.1490 loss,  94.4% accuracy, 0.9706 recall, 0.0344 precision, 0.0665 f1_score\n",
      "2024/04/25 17:32:22 INFO     TrainingLoop:150:logMetrics E20 val_neg  0.1491 loss,  94.4% correct (15723 of 16648)\n",
      "2024/04/25 17:32:22 INFO     TrainingLoop:161:logMetrics E20 val_pos  0.0893 loss,  97.1% correct (33 of 34)\n"
     ]
    }
   ],
   "source": [
    "from nodule_classifier.training_loop import build_training_loop\n",
    "\n",
    "\n",
    "loop = build_training_loop()\n",
    "loop.run(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
